import snowflake.connector

# Connectio string
conn = snowflake.connector.connect(
                user='',
                password='',
                account='uhgdwaas.east-us-2.azure',
                #warehouse='COMPUTE_WH',
                database='CDW_PRD_CALL_DB',
                schema='CDW_IVR_BASE_VIEW_SC'
                )
                
                
 #How to Connect Python and SQL Server
import pyodbc
conn = pyodbc.connect("Driver={SQL Server Native Client 11.0};"
                      "Server=thor-db.optum.com;"
                      "Database=THOR;"
                      "Trusted_Connection=yes;")

cursor = conn.cursor()
cursor.execute('SELECT Top 10 FROM GENESYS.V_CHAT_CCS_GIM_AGENT_SUMMARY_ERA')

for row in cursor:
    print('row = %r' % (row,))
    
    
	1. Connecting MySQL Server
	from sqlalchemy import create_engine
	import pymysql
	
	db_connection_str = 'mysql+pymysql://eem327_own:p5BJyIW@dbvrd46413/eem327'
	db_connection = create_engine(db_connection_str)
	data = pd.read_sql('select * from edi_analysis limit 100', con=db_connection)
	
	2. Connecting to SQL Server
	import numpy as np
	import re
	import nltk
	from sklearn.datasets import load_files
	#nltk.download('stopwords')
	import pickle
	from nltk.corpus import stopwords
	import pyodbc
	conn = pyodbc.connect("Driver={SQL Server Native Client 11.0};"
	                      "Server=thor-db.optum.com;"
	                      "Database=THOR;"
	                      "Trusted_Connection=yes;")
	
	cursor = conn.cursor()
	
	query = "SELECT * FROM [THOR].[GENESYS].[V_CHAT_CCS_GIM_TRANSCRIPTS_ERA] where ROW_DATE between '2023-01-01' and '2023-01-05'"
	
	df = pd.read_sql_query(query,conn)
	print(df)
	print(type(df))
	conn.close()
	

	2. Uploading data on MYSQL server
	from sqlalchemy import create_engine
	import pymysql
	import os
	import pandas as pd
	
	tableName   = "edi_analysis_predict_new"
	dataFrame   = df1           
	
	sqlEngine       = create_engine('mysql+pymysql://eem_mysql:TSEb3+=m@dbvrd46413/eem_a', pool_recycle=3600)
	dbConnection    = sqlEngine.connect()
	
	try:
	    frame           = dataFrame.to_sql(tableName, dbConnection, if_exists='replace');
	except ValueError as vx:
	    print(vx)
	except Exception as ex:   
	    print(ex)
	else:
	    print("Table %s created successfully."%tableName);   
	finally:
	    dbConnection.close()
	
	
	3. Downloading data from MySQL table to excel
	from sqlalchemy import create_engine
	import pymysql
	import os
	import pandas as pd
	
	file='MYSQL_download.xlsx'
	
	qry = "select distinct t.*, j.*  from eem327.quest_analysis t left join eem327.address_standarization j on (ifnull(upper(t.orig_adr1), '') = ifnull(upper(j.orig_adr1), '') and ifnull(upper(t.orig_adr2), '') = ifnull(upper(j.orig_adr2), '') and ifnull(upper(t.orig_city), '') = ifnull(upper(j.orig_city), '') and ifnull(upper(t.orig_state), '') = ifnull(upper(j.orig_state), '') and ifnull(upper(replace(replace(t.orig_zip, '-', ''), ' ', '')), '') = ifnull(upper(j.orig_zip), ''))"
	
	
	Engine = 'mysql+pymysql://eem_mysql:TSEb3+=m@dbvrd46413/eem_a' #'mysql+pymysql://mysql_user:mysql_password@mysql_host/mysql_db'
	MyEngine = create_engine(Engine)
	print('\t Downloading...')
	
	data = pd.read_sql(qry, con=MyEngine)
	    
	cwd = os.getcwd()
	os.chdir(cwd)
	data.to_excel (file, index = False, header=True)
	print('\tDownload Complete:', cwd+'\\'+file)
	Engine.close()
	
	
	

	1. Connecting with MS SQL Server
	import pyodbc
	
	cnxn = pyodbc.connect('DRIVER={SQL Server Native Client 11.0};SERVER=dbsed4432;DATABASE=pera;Trusted_Connection=yes')
	cursor = cnxn.cursor()
	
	2. Executing SQL query
	cursor.execute("SELECT * FROM pera.dbo.sutter_exhibit_b")
	row = cursor.fetchone()
	while row:
	    print (row)
	    row = cursor.fetchone()
	
	3. Updating MS SQL server 
	import pyodbc
	cnxn = pyodbc.connect('DRIVER={SQL Server Native Client 11.0};SERVER=dbsed4432;DATABASE=pera;Trusted_Connection=yes')
	cursor = cnxn.cursor()
	df = pd.read_excel("C:/Users/rbalani1/Desktop/EEM/SQL10.xlsx")
	for index, row in df.iterrows():
	     cursor.execute("INSERT INTO pera.dbo.sutter ([L1],[L2],[L3]) values(?,?,?)", row['L1'], row['L2'], row['L3'])
	cnxn.commit()
	cursor.close()
	
	4. To bring last column in front
	#First column
	cols = list(df1.columns)
	cols = [cols[-1]] + cols[:-1]
	df1 = df1[cols]
	
	5. pandas drop a column with drop function
Df1.drop(['pop'], axis=1)
	X= df1.drop(['L1','L2','L3','City','State','Address','Tax_ID','Name','DefHel','Dun','NDB','Genesis'],axis=1)
	
	6. Getting desired columns
	df1 = df.iloc[:, [1,3,4,5,8]]
	
	7. To drop columns which have less than 80% data
	limitPer = len(data) * .80
	df1 = data.dropna(thresh=limitPer,axis=1)
	
	8. To see data health
	print(df2.shape)
	for i in df2.columns:
	    print(i, "---> Unique values=", df2[i].nunique(),"|||| NA Values=", sum(pd.isnull(df2[i])), "|||type=", df2[i].dtype)
	
	9. To see missing data
	def miss_data(df):
	    x = ['column_name','missing_data', 'missing_in_percentage']
	    missing_data = pd.DataFrame(columns=x)
	    columns = df.columns
	    for col in columns:
	        icolumn_name = col
	        imissing_data = df[col].isnull().sum()
	        imissing_in_percentage = (df[col].isnull().sum()/df[col].shape[0])*100
	
	        missing_data.loc[len(missing_data)] = [icolumn_name, imissing_data, imissing_in_percentage]
	    print(missing_data)
	miss_data(data)
	
	10. Cleaning the text sentences so that punctuation marks, stop words & digits are removed  
	def clean(doc):
	    stop_free = " ".join([i for i in doc.lower().split() if i not in stop])
	    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)
	    normalized = " ".join(lemma.lemmatize(word) for word in punc_free.split())
	    processed = re.sub(r"\d+","",normalized)
	    y = processed.split()
	    return y
	
	11. To see unique counts in dataset:    df.nunique(),        df.agg(['count', 'size', 'nunique'])

10 . To change directory and save file:
	File = 'file_name.xlsx'
	cwd = os.getcwd()
	os.chdir(cwd)
	data.to_excel (file, index = False, header=True)
	print('\tDownload Complete:', cwd+'\\'+file)
	
	11. To keep 0 or in 1 in any pandas column:  result['STATE'] = result['STATE'].apply(lambda x: 0 if x <1 else 1)

	12. Filling pandas column on basis of condition:
	conditions = [(result['CITY'] == 1) & (result['STATE'] == 1),
	                         (result['CITY'] == 0) & (result['STATE'] == 0)]
	choices = [1, 0]
	result['New'] = np.select(conditions, choices, default=np.nan)
	
	13. Dropping NAN values: result = result.dropna(axis=0, subset=['New'])
	
	14. Dropping 0 values: result = result[(result[['New']] != 0).all(axis=1)]
	
	15. Sorting values of column in descending order: result = result.sort_values('TotalScore',ascending=False)

	16. To combine dataframe and function output:
	frames = [df1, output1, output2, output3, output4, output5]
	result = pd.concat(frames, axis=1)   # side by side concatenate
	result = pd.concat(frames, axis=0)   # stack type concatenate
	
	17. To convert list into dataframe and csv
	df = pd.DataFrame(entity_pairs, columns=["entity", "pair"])
	df.to_csv('list.csv', index=False)
	
	18. To change yes or No into  0 or 1
	data['claim_status'] = df['claim_status_code'].apply(lambda x: 1 if x == 'A' else 0)
	df["SeniorCitizen"] = df["SeniorCitizen"].replace({"Yes":1,"No":0})
	
	19. Adding new column in dataframe
	output.insert(loc=0, column='Dataset', value='DnB')
	
	20. Value Counts
	EDI.stb.freq(['Billing_Name'])
	
	21. Text Cleaning
	documents = []
	
	from nltk.stem import WordNetLemmatizer
	
	stemmer = WordNetLemmatizer()
	
	for sen in range(0, len(X)):
	    # Remove all the special characters
	    document = re.sub(r'\W', ' ', str(X[sen]))
	    
	    # remove all single characters
	    document = re.sub(r'\s+[a-zA-Z]\s+', ' ', document)
	    
	    # Remove single characters from the start
	    document = re.sub(r'\^[a-zA-Z]\s+', ' ', document) 
	    
	    # Substituting multiple spaces with single space
	    document = re.sub(r'\s+', ' ', document, flags=re.I)
	    
	    # Removing prefixed 'b'
	    document = re.sub(r'^b\s+', '', document)
	    
	    # Converting to Lowercase
	    document = document.lower()
	    
	    # Lemmatization
	    document = document.split()
	
	    document = [stemmer.lemmatize(word) for word in document]
	    document = ' '.join(document)
	    
	    documents.append(document)


	22. Remove first 22 character from string
	df1['TRANSCRIPT_TEXT'] = df1['TRANSCRIPT_TEXT'].str[22:]
	df1['TRANSCRIPT_TEXT'] 

	23. Tableau Latest Month
{MAX(DATETRUNC('month',[Last Logged In]))} = (DATETRUNC('month',[Last Logged In]))

